---
title: Evaluation of COVID-19 Cases Forecasters 
subtitle: Parametrized Report
date: "`r format(Sys.time(), '%d %B %Y')`"
abstract: |
  This notebook is a template for evaluating COVID-19 cases forecast submissions from COVIDhub. After inputting a set of parameters (forecasters, COVID signals, etc), the template yields a comprehensive report on the predictions of COVID forecasters as well as their performance compared to the ground truth. The visualizations generated by the template offer an intuitive way to compare the accuracy of forecasters across all US states.
output: 
  html_document:
    code_folding: hide
params:
  forecasters:
    label: "Forecasters:"
    choices: [BPagano-RtDriven,CEID-Walk,Covid19Sim-Simulator, CovidActNow-SEIR_CAN, CovidAnalytics-DELPHI,COVIDhub-baseline, COVIDhub-ensemble,COVIDhub-trained_ensemble, CU-select,DDS-NBDS, Geneva-DetGrowth, Google_Harvard-CPF, IEM_MED-CovidProject, IHME-CurveFit, IowaStateLW-STEM, IQVIA_ACOE-STAN,IUPUI-HkPrMobiDyR,JCB-PRM,JHU_CSSE-DECOM,JHU_IDD-CovidSP, JHU_UNC_GAS-StatMechPool , JHUAPL-Bucky,Karlen-pypm, KITmetricslab-select_ensemble, LANL-GrowthRate,  LNQ-ens1, Microsoft-DeepSTIA, MIT_ISOLAT-Mixtures,MIT-Cassandra,MOBS-GLEAM_COVID,MSRA-DeepST,MUNI-ARIMA,OliverWyman-Navigator, OneQuietNight-ML,RobertWalraven-ESG,SigSci-TS,TTU-squider,UChicagoCHATTOPADHYAY-UnIT, UCLA-SuEIR, UCSB-ACTS,UMich-RidgeTfReg,USACE-ERDC_SEIR,USC-SI_kJalpha, UVA-Ensemble,Wadhwani_AI-BayesOpt]
    value: [CovidAnalytics-DELPHI,COVIDhub-baseline, COVIDhub-ensemble,COVIDhub-trained_ensemble, CU-select,Karlen-pypm]
    input: select
    multiple: TRUE
  primary_forecaster:
    label: "Primary forecaster:"
    choices: [BPagano-RtDriven,CEID-Walk,Covid19Sim-Simulator, CovidActNow-SEIR_CAN, CovidAnalytics-DELPHI,COVIDhub-baseline, COVIDhub-ensemble,COVIDhub-trained_ensemble, CU-select,DDS-NBDS, Geneva-DetGrowth, Google_Harvard-CPF, IEM_MED-CovidProject, IHME-CurveFit, IowaStateLW-STEM, IQVIA_ACOE-STAN,IUPUI-HkPrMobiDyR,JCB-PRM,JHU_CSSE-DECOM,JHU_IDD-CovidSP, JHU_UNC_GAS-StatMechPool , JHUAPL-Bucky,Karlen-pypm, KITmetricslab-select_ensemble, LANL-GrowthRate,  LNQ-ens1, Microsoft-DeepSTIA, MIT_ISOLAT-Mixtures,MIT-Cassandra,MOBS-GLEAM_COVID,MSRA-DeepST,MUNI-ARIMA,OliverWyman-Navigator, OneQuietNight-ML,RobertWalraven-ESG,SigSci-TS,TTU-squider,UChicagoCHATTOPADHYAY-UnIT, UCLA-SuEIR, UCSB-ACTS,UMich-RidgeTfReg,USACE-ERDC_SEIR,USC-SI_kJalpha, UVA-Ensemble,Wadhwani_AI-BayesOpt]
    value: COVIDhub-baseline
    input: select  
  colorblind_palette: TRUE
  weeks: 
    label: "Weeks"
    value: [1,2,3,4]
    input: select
    choices: [1,2,3,4]
    multiple: True
  printcode: TRUE
editor_options: 
  chunk_output_type: console
---

```{r common-stuff, echo=FALSE, message=FALSE, warning=FALSE}
# Package installation
knitr::opts_chunk$set(autodep = TRUE, fig.align = "center", message = FALSE, warning = FALSE, echo=params$printcode)
library(covidcast)
library(evalcast)
library(modeltools)
library(zookeeper)
library(namespace)
library(downloadthis)
library(knitr)
library(sf)
library(Cairo)
library(tidyverse)
library(viridis)
library(ggplot2)
library(plotly)
library(here)
```

### Retrieving Forecast Data
Every week, forecasters submit their predictions to COVID-19 ForecastHub. In this report, we rely on an AWS bucket that contains the estimates of a handful of signals (e.g., COVID death, cases, hospitalization, etc). Furthermore, the AWS server stores an array of evaluation metrics of these forecasts (e.g., Absolute Error, Weighted Interval Score, and 80% Coverage). Alternatively, the data can be retrieved from the publicly accessible [covidcast](https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html) and [covideval](https://cmu-delphi.github.io/covidcast/evalcastR/) APIs.

```{r, results = 'asis'}
aheads  <- as.numeric(params$weeks)
primary_forecaster <- params$primary_forecaster

url_case <- "https://forecast-eval.s3.us-east-2.amazonaws.com/score_cards_state_cases.rds"
download.file(url_case, "eval_cases.RDS") # download to disk
scores1 <- readRDS(paste0(here(), "/eval_cases.RDS"))
scores <- subset(scores1,  forecaster %in% params$forecasters)

our_pred_dates <- 
  scores %>%
  filter(forecaster == primary_forecaster) 

our_pred_dates <- unique(our_pred_dates$forecast_date)
# n_dates <- length(our_pred_dates)
# forecast_dates <- our_pred_dates[n_dates- 2 *5:2]
forecast_dates <- our_pred_dates


scores$forecast_date <- 
  if_else(scores$forecaster %in% c("Karlen-pypm", "CU-select"), scores$forecast_date + 1, scores$forecast_date)

scores <- subset(scores, forecast_date %in% forecast_dates & ahead <= aheads)
results <- intersect_averagers(scores, c("forecaster"), c("forecast_date", "geo_value")) %>%
  select(c("ahead", "geo_value", "forecaster","forecast_date", "data_source", "signal","target_end_date","incidence_period","actual","wis","ae","cov_80"))

# kable(results %>%
#   group_by(forecast_date) %>%
#   summarise(n_distinct(geo_value)))
```

**The target forecast dates are:** <br/> `r forecast_dates` 

**The template will compile data of the following forecasters:** <br/> `r params$forecasters`. 

**The primary forecaster:** <br/> `r primary_forecaster`

$$\\[.07in]$$
To promote the flexibility to replicate the report, the data used in this report can be easily downloaded as a CSV file. By doing so, the user can generate customized plots or even include their own forecaster.  

```{r download data}
results %>%
  download_this(
    output_name = "results",
    output_extension = ".csv",
    button_label = "Download Cases Evaluation",
    button_type = "success",
    has_icon = TRUE,
    csv2 = FALSE,
    icon = "fa fa-save"
  )
```

<!-- ```{r evaluate-predictions, messages=F, warning=F} -->
<!-- # for county prediction, set geo_type = "county" -->
<!-- results <- evaluate_covid_predictions(all_predictions, -->
<!--                                       backfill_buffer = 0, -->
<!--                                       geo_type = "state") %>% -->
<!--   intersect_averagers(c("forecaster"), c("forecast_date", "geo_value")) -->

<!-- all_predictions %>% -->
<!--   group_by(forecast_date) %>% -->
<!--   summarise(n_distinct(geo_value)) -->
<!-- ``` -->


### Overall Absolute Error, Weighted Interval Score, and 80% Coverage {.tabset}
The primary metrics used in evaluating the performance of COVID forecasters are:

#### Overall Weighted Interval Score
By Forecast Dates

The Weighted Interval Score can be interpreted as a generalization of the absolute error to probabilistic forecasts and allows for a decomposition into a measure of sharpness (spread) and penalties for over- and under prediction. With certain weight settings, the WIS is an approximation of the continuous ranked probability score, and can also be calculated in the form of an average pinball loss. A smaller WIS indicates better performance.

``` {r overall wis}
weeks.label = c("1 week ahead", "2 weeks ahead", "3 weeks ahead", "4 weeks ahead")
names(weeks.label) = c(1, 2, 3, 4)

subtitle = sprintf("Forecasts made over %s to %s",
                   format(min(forecast_dates), "%B %d, %Y"),
                   format(max(forecast_dates), "%B %d, %Y"))
plot_wis <-
  plot_canonical(results, 
                 x = "forecast_date", 
                 y = "wis", 
                 aggr = mean,
                 grp_vars = c("forecaster","ahead"), 
                 facet_rows = "ahead") + 
  labs(title = subtitle, 
       x = "Forecast Dates", 
       y = "Mean WIS",
       color = "Forecasters") +
  geom_point(aes(text=sprintf("Forecast Date: %s<br>Mean WIS: %s <br>Forecaster: %s", 
                              forecast_date, 
                              round(wis, digits = 2),
                              color)),
             alpha = 0.05) +
  facet_wrap(~ahead, nrow = 4, labeller = labeller(ahead=weeks.label)) +
  theme(strip.background = element_rect(fill = "white")) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = "center")) + 
  scale_y_log10()

if (params$colorblind_palette) {
  plot_wis <- plot_wis + 
    scale_color_viridis_d()
}

ggplotly(plot_wis, tooltip="text", height=800, width= 1000) %>% 
  layout(hoverlabel = list(bgcolor = "white"))
```

#### Overall Absolute Error
By Weeks Ahead

Absolute Error is the difference between the measured value and the “true” value. The absolute error of a forecast is the absolute value of the difference between the actual value and the point forecast. The point forecast of a model when not provided explicitly is taken to be the 50% quantile of the forecast distribution.

```{r overall ae}
plot_ae <-
  plot_canonical(results, 
                 x = "ahead", 
                 y = "ae", 
                 aggr = mean) +
  labs(title = subtitle, x= "Weeks Ahead", y = "Mean AE",color='Forecasters') +  
#  geom_line(aes(linetype=forecaster, color=forecaster)) +
  geom_point(aes(color=forecaster, text=sprintf("Weeks Ahead: %s<br>Average Error: %s <br>Forecaster: %s", 
                              ahead, 
                              round(ae, digits=2),
                              color)),
             alpha = 0.05) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_y_log10()

if (params$colorblind_palette) {
  plot_ae <- plot_ae + 
    scale_color_viridis_d()
}

plot_ae<- ggplotly(plot_ae, tooltip="text", width=1000) 

#adjust y-axis label
plot_ae[['x']][['layout']][['annotations']][[2]][['x']] <- -0.05
plot_ae %>% layout(margin = list(l = 75), hoverlabel = list(bgcolor = "white"))

```

#### Overall Coverage 80
By Forecast Dates

Coverage is estimated on a particular date by computing the proportion of locations for which a forecaster's interval includes the actual value on that date. A perfectly calibrated forecaster would have each interval's empirical coverage matching its nominal coverage. In the plot, this corresponds to being on the horizontal black line. Overconfidence corresponds to being below the line while underconfidence corresponds to being above the line.

``` {r overall coverage80}
plot_cov80 <-
  plot_canonical(results, 
                 x = "forecast_date", 
                 y = "cov_80", 
                 aggr = mean,
                 grp_vars = c("forecaster","ahead"), 
                 facet_rows = "ahead") +
  labs(title = subtitle, x= "Forecast date", y = "Mean Coverage 80", color='Forecasters') +
  geom_point(aes(text = sprintf("Forecast Date: %s<br>Coverage: %s <br>Forecaster: %s", 
                                forecast_date, 
                                round(cov_80, digits = 2),
                                color)),
             alpha = 0.05) +
  facet_wrap(~ahead, nrow = 4, labeller = labeller(ahead = weeks.label)) +
  theme(strip.background = element_rect(fill = "white")) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = "center")) +
  geom_line(mapping = aes(y = .8), )

if (params$colorblind_palette) {
  plot_cov80 <- plot_cov80 + 
    scale_color_viridis_d()
}

plot_cov80 <- ggplotly(plot_cov80, tooltip="text", height=800, width=1000) 

#adjust y-axis label
plot_cov80[['x']][['layout']][['annotations']][[2]][['x']] <- -0.05
plot_cov80 %>% layout(margin = list(l = 75), hoverlabel = list(bgcolor = "white"))

```

### Mean Geometric Relative WIS {.tabset}

Relative to COVIDhub-baseline (primary forecaster); scale first then take the geometric mean, ignoring a few 
0's.

#### By Weeks Ahead

```{r, message = FALSE, warning = FALSE}
geom_mean <- function(x) prod(x)^(1/length(x))
#geom_mean <- exp(mean(log((x+1)/(y+1)))) #still need to figure this out

mean_wis <- 
  plot_canonical(results %>% 
                   filter(wis > 0), 
                 x = "ahead", 
                 y = "wis", 
                 aggr = geom_mean,
                 base_forecaster = primary_forecaster, 
                 scale_before_aggr = TRUE) + 
  labs(title = subtitle, 
       x = "Weeks Ahead", 
       y = "Geometric mean relative WIS", 
       color = "Forecasters") +
  geom_point(aes(text = sprintf("Weeks Ahead: %s<br>WIS: %s <br>Forecaster: %s", 
                                ahead, 
                                round(wis, digits = 2),
                                color)),
             alpha = 0.05) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = "center")) +
  geom_line(mapping = aes(y = 1))

if (params$colorblind_palette) {
  mean_wis <- mean_wis + 
    scale_color_viridis_d()
}

mean_wis <- ggplotly(mean_wis, tooltip="text", width= 1000)

#adjust y-axis label
mean_wis[['x']][['layout']][['annotations']][[2]][['x']] <- -0.05
mean_wis%>% layout(margin = list(l = 75), hoverlabel = list(bgcolor = "white"))
```

#### By Forecast Dates

```{r}
mean_wis_forecast_date <- 
plot_canonical(results %>% 
                 filter(wis > 0), 
               x = "forecast_date", 
               y = "wis", 
               aggr = geom_mean, 
               facet_rows = "ahead",
               grp_vars = c("forecaster", "ahead"),
               base_forecaster = "COVIDhub-baseline", 
               scale_before_aggr = TRUE) +
  theme(legend.position = "bottom") + 
  labs(title = subtitle, 
       x = "Forecast date", 
       y = "Geometric mean relative WIS", 
       color = "Forecasters") +
  geom_point(aes(text = sprintf("Forecast Date: %s<br>WIS: %s <br>Forecaster: %s", 
                                forecast_date, 
                                round(wis, digits = 2),
                                color)),
             alpha = 0.05) +
  facet_wrap(~ahead, nrow = 4, labeller = labeller(ahead = weeks.label)) +
  theme(strip.background = element_rect(fill = "white")) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = "center")) +
  geom_line(mapping = aes(y = 1))

if (params$colorblind_palette) {
  mean_wis_forecast_date <- mean_wis_forecast_date + 
    scale_color_viridis_d()
}

mean_wis_forecast_date<- ggplotly(mean_wis_forecast_date, tooltip = "text", height=800, width= 1000)

#adjust y-axis label
mean_wis_forecast_date[['x']][['layout']][['annotations']][[2]][['x']] <- -0.05
mean_wis_forecast_date %>% layout(margin = list(l = 75), hoverlabel = list(bgcolor = "white"))
```

```{r, message = FALSE, warning = FALSE, include = FALSE}
## Scores by target date (not forecast date) 

# target_wis <-
#   plot_canonical(results, x = "target_end_date", y = "wis", aggr = mean,
#                dots = TRUE, grp_vars = "forecaster") + 
#   labs(title = subtitle, x = "Target date", y = "Mean WIS", color='Forecasters') +
#   scale_y_log10() +
#   geom_point(aes(text=sprintf("Target End Date: %s<br>WIS: %s <br>Forecaster: %s", target_end_date, round(wis, digits=2),color)),alpha = 0.05) +
#   theme_minimal() +
#   theme(plot.title = element_text(hjust = 'center'))
# 
# target_wis_ahead <-
#   plot_canonical(results, x = "target_end_date", y = "wis", aggr = mean,
#                dots = TRUE, grp_vars = c("forecaster", "ahead"), 
#                facet_rows = "ahead") +
#   labs(title = subtitle, x = "Target date", y = "Mean WIS", color='Forecasters') +
#   scale_y_log10() +
#   geom_point(aes(text=sprintf("Target End Date: %s<br>WIS: %s <br>Forecaster: %s", target_end_date, round(wis, digits=2),color)),alpha = 0.05)+
#   facet_wrap(~ahead, nrow = 4, labeller = labeller(ahead=weeks.label))+
#   theme(strip.background = element_rect(fill = "white")) +
#   theme_minimal() +
#   theme(plot.title = element_text(hjust = 'center'))
# 
# ggplotly(target_wis, tooltip="text", width= 1000) %>% layout(hoverlabel=list(bgcolor='white'))
# ggplotly(target_wis_ahead, tooltip="text", height=800, width= 1000) %>% layout(hoverlabel=list(bgcolor='white'))
```

### Maps {.tabset}
To contextualize the forecast evaluations, the following tabs illustrates the performance of COVID forecasts across all US states over forecast dates and weeks ahead. Note that the results are scaled by population.

```{r maps-processing, warning=FALSE}
library(sf)
maps <- results %>%
  group_by(geo_value, forecaster) %>%
  summarise(across(wis:cov_80, mean)) %>%
  left_join(animalia::state_population, by = "geo_value") %>%
  mutate(across(wis:cov_80, ~ .x / population * 1e5))%>%
  pivot_longer(wis:cov_80, names_to = "score") %>%
  group_by(score) %>%
  mutate(time_value = Sys.Date(),
         r = max(value)) %>%
  group_by(forecaster, .add = TRUE) %>%
  group_split()

# for county prediction, set geo_type = "county"
maps <- purrr::map(maps, 
                   ~as.covidcast_signal(
                     .x, signal = .x$score[1], 
                     data_source = .x$forecaster[1], 
                     geo_type = "state"))

maps <- purrr::map(maps,
                   ~plot(.x, 
                         choro_col = scales::viridis_pal()(3),
                         range = c(0,.x$r[1])))
nfcasts <- length(unique(results$forecaster))
```

#### Mean Weighted Interval Score

The Weighted Interval Score can be interpreted as a generalization of the absolute error to probabilistic forecasts and allows for a decomposition into a measure of sharpness (spread) and penalties for over- and under prediction. With certain weight settings, the WIS is an approximation of the continuous ranked probability score, and can also be calculated in the form of an average pinball loss. A smaller WIS indicates better performance.

```{r map-wis, fig.width=12, fig.height=8}
cowplot::plot_grid(plotlist = maps[((nfcasts*2)+1):length(maps)], ncol = 3)
```

#### Mean Absolute Error

Absolute Error is the difference between the measured value and the “true” value. The absolute error of a forecast is the absolute value of the difference between the actual value and the point forecast. The point forecast of a model when not provided explicitly is taken to be the 50% quantile of the forecast distribution.

```{r map-ae, fig.width=12, fig.height=8}
# original code
cowplot::plot_grid(plotlist = maps[1:nfcasts], ncol = 3)
```

#### Mean Coverage 80

Coverage is estimated on a particular date by computing the proportion of locations for which a forecaster's interval includes the actual value on that date. A perfectly calibrated forecaster would have each interval's empirical coverage matching its nominal coverage. In the plot, this corresponds to being on the horizontal black line. Overconfidence corresponds to being below the line while underconfidence corresponds to being above the line.

```{r map-cov80, fig.width=12, fig.height=8}
cowplot::plot_grid(plotlist = maps[(nfcasts+1):(nfcasts*2)], ncol = 3)
```